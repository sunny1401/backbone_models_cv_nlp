{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "745c21e6",
   "metadata": {},
   "source": [
    "#### Download data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698cdb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_utils.src import KaggleDataApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e400554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved to:   c:\\users\\sankr\\documents\\projects\\git_work\\experiments\\data\\facial-keypoints-detection.zip\n"
     ]
    }
   ],
   "source": [
    "kda = KaggleDataApi(call_path = CURRENT_ROOT_DIR)\n",
    "kda.download_kaggle_dataset(dataset_name=\"facial_keypoints_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0617c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c:\\\\users\\\\sankr\\\\documents\\\\projects\\\\git_work\\\\experiments\\\\data\\\\facial-keypoints-detection',\n",
       " ['IdLookupTable.csv', 'SampleSubmission.csv', 'test.zip', 'training.zip'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kda.unzip_and_return_folder_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b04c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in [\"test.zip\", \"training.zip\"]:\n",
    "    complete_path = os.path.join(root_folder, file_name)\n",
    "    with zipfile.ZipFile(complete_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3aca0",
   "metadata": {},
   "source": [
    "#### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12882973",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"c:\\\\users\\\\sankr\\\\documents\\\\projects\\\\git_work\\\\experiments\\\\data\\\\facial-keypoints-detection\"\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf43e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IdLookupTable.csv',\n",
       " 'SampleSubmission.csv',\n",
       " 'test',\n",
       " 'test.csv',\n",
       " 'test.zip',\n",
       " 'training',\n",
       " 'training.csv',\n",
       " 'training.zip']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc6cec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = os.path.join(root_folder, \"IdLookupTable.csv\")\n",
    "submission_file = os.path.join(root_folder, \"SampleSubmission.csv\")\n",
    "test_data = os.path.join(root_folder, \"test.csv\")\n",
    "train_data = os.path.join(root_folder, \"training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d23e640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(root_folder, train_data.replace(\"csv\", \"\")), exist_ok =True)\n",
    "os.makedirs(os.path.join(root_folder, test_data.replace(\"csv\", \"\")), exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84a7a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf47a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61c8bbe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cfce590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Image\"] = df.Image.apply(lambda x: np.array(x.split(\" \"), dtype=\"float\"))\n",
    "df[\"Image\"] = df.Image.apply(lambda pixel: pixel.reshape(96, 96, 1))\n",
    "df[\"Image\"] = df.Image.apply(lambda pixel: pixel/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc943377",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df.pop(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c65b6da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
       "       'right_eye_center_y', 'left_eye_inner_corner_x',\n",
       "       'left_eye_inner_corner_y', 'left_eye_outer_corner_x',\n",
       "       'left_eye_outer_corner_y', 'right_eye_inner_corner_x',\n",
       "       'right_eye_inner_corner_y', 'right_eye_outer_corner_x',\n",
       "       'right_eye_outer_corner_y', 'left_eyebrow_inner_end_x',\n",
       "       'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x',\n",
       "       'left_eyebrow_outer_end_y', 'right_eyebrow_inner_end_x',\n",
       "       'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x',\n",
       "       'right_eyebrow_outer_end_y', 'nose_tip_x', 'nose_tip_y',\n",
       "       'mouth_left_corner_x', 'mouth_left_corner_y', 'mouth_right_corner_x',\n",
       "       'mouth_right_corner_y', 'mouth_center_top_lip_x',\n",
       "       'mouth_center_top_lip_y', 'mouth_center_bottom_lip_x',\n",
       "       'mouth_center_bottom_lip_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2de01a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.93333333],\n",
       "        [0.9254902 ],\n",
       "        [0.92941176],\n",
       "        ...,\n",
       "        [0.98039216],\n",
       "        [0.98039216],\n",
       "        [0.98039216]],\n",
       "\n",
       "       [[0.92156863],\n",
       "        [0.93333333],\n",
       "        [0.9254902 ],\n",
       "        ...,\n",
       "        [0.97647059],\n",
       "        [0.98039216],\n",
       "        [0.98431373]],\n",
       "\n",
       "       [[0.92941176],\n",
       "        [0.9254902 ],\n",
       "        [0.92941176],\n",
       "        ...,\n",
       "        [0.98431373],\n",
       "        [0.98431373],\n",
       "        [0.98039216]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.72941176],\n",
       "        [0.71764706],\n",
       "        [0.70980392],\n",
       "        ...,\n",
       "        [0.20392157],\n",
       "        [0.22352941],\n",
       "        [0.23529412]],\n",
       "\n",
       "       [[0.74117647],\n",
       "        [0.7372549 ],\n",
       "        [0.81176471],\n",
       "        ...,\n",
       "        [0.23921569],\n",
       "        [0.27058824],\n",
       "        [0.30588235]],\n",
       "\n",
       "       [[0.74901961],\n",
       "        [0.72156863],\n",
       "        [0.72156863],\n",
       "        ...,\n",
       "        [0.2745098 ],\n",
       "        [0.29411765],\n",
       "        [0.35294118]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca3c54c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(images[0], np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "920ac9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b4391dde50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17a4c5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.93333333],\n",
       "        [0.9254902 ],\n",
       "        [0.92941176],\n",
       "        ...,\n",
       "        [0.98039216],\n",
       "        [0.98039216],\n",
       "        [0.98039216]],\n",
       "\n",
       "       [[0.92156863],\n",
       "        [0.93333333],\n",
       "        [0.9254902 ],\n",
       "        ...,\n",
       "        [0.97647059],\n",
       "        [0.98039216],\n",
       "        [0.98431373]],\n",
       "\n",
       "       [[0.92941176],\n",
       "        [0.9254902 ],\n",
       "        [0.92941176],\n",
       "        ...,\n",
       "        [0.98431373],\n",
       "        [0.98431373],\n",
       "        [0.98039216]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.72941176],\n",
       "        [0.71764706],\n",
       "        [0.70980392],\n",
       "        ...,\n",
       "        [0.20392157],\n",
       "        [0.22352941],\n",
       "        [0.23529412]],\n",
       "\n",
       "       [[0.74117647],\n",
       "        [0.7372549 ],\n",
       "        [0.81176471],\n",
       "        ...,\n",
       "        [0.23921569],\n",
       "        [0.27058824],\n",
       "        [0.30588235]],\n",
       "\n",
       "       [[0.74901961],\n",
       "        [0.72156863],\n",
       "        [0.72156863],\n",
       "        ...,\n",
       "        [0.2745098 ],\n",
       "        [0.29411765],\n",
       "        [0.35294118]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70a315",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cv.pytorch.data_loader.use_cases.facial_keypoint_detection.dataloader import FacialKeypointDataLoader\n",
    "from src.cv.pytorch.models.configs import ModelTrainingConfig, ModelDataConfig\n",
    "from src.cv.pytorch.models.use_cases.facial_keypoint_detection.utils import show_key_points_on_images\n",
    "from src import CURRENT_ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad367695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3f063",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fkdl = FacialKeypointDataLoader(\n",
    "    dataset_name=\"faces\", \n",
    "    data_type = \"csv\",\n",
    "    data_file=r\"data/facial-keypoints-detection/training.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fkdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5d218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial config for training\n",
    "model_config = ModelTrainingConfig(\n",
    "    learning_rate=0.01, batch_size=256, epochs=50, \n",
    ")\n",
    "data_config = ModelDataConfig(train_size=0.8, validation_size=0.2, dataset_size=len(fkdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba20ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    fkdl, batch_size=model_config.batch_size, num_workers=4, sampler=data_config.train_sampler\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    fkdl, batch_size=model_config.batch_size, num_workers=4, sampler=data_config.validation_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e50d45e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot resize an array that references or is referenced\nby another array in this way.\nUse the np.resize function or refcheck=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mshow_key_points_on_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfkdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\sankr\\documents\\projects\\git_work\\experiments\\src\\cv\\pytorch\\models\\use_cases\\facial_keypoint_detection\\utils.py:36\u001b[0m, in \u001b[0;36mshow_key_points_on_images\u001b[1;34m(dataset, idx)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_key_points_on_images\u001b[39m(\n\u001b[0;32m     29\u001b[0m     dataset, \n\u001b[0;32m     30\u001b[0m     idx, \n\u001b[0;32m     31\u001b[0m ):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m    Function plots image and associated keypoint on the image for the input idx\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     37\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m     38\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\sankr\\documents\\projects\\git_work\\experiments\\src\\cv\\pytorch\\data_loader\\use_cases\\facial_keypoint_detection\\dataloader.py:121\u001b[0m, in \u001b[0;36mFacialKeypointDataLoader.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    116\u001b[0m     keypoints \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mimage_labels\u001b[38;5;241m.\u001b[39miloc[idx, :])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    119\u001b[0m     sample \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacial_landmarks\u001b[39m\u001b[38;5;124m\"\u001b[39m: keypoints}\n\u001b[1;32m--> 121\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_cuda_test\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\users\\sankr\\documents\\projects\\git_work\\experiments\\src\\cv\\pytorch\\data_loader\\use_cases\\facial_keypoint_detection\\transforms.py:93\u001b[0m, in \u001b[0;36mResize.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m---> 93\u001b[0m         \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m         image\u001b[38;5;241m.\u001b[39mresize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot resize an array that references or is referenced\nby another array in this way.\nUse the np.resize function or refcheck=False"
     ]
    }
   ],
   "source": [
    "show_key_points_on_images(dataset=fkdl, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_view = [fkdl[i] for i in range(50, 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db11f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cv.pytorch.models.use_cases.facial_keypoint_detection.utils import multi_view_image_keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_view_image_keypoints(list_of_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249182e",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c746d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cv.pytorch.models.use_cases.facial_keypoint_detection.facial_keypoint_vanilla_cnn import FacialKeypointVCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7002e10",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'linear_layers' and 'dropout_threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m]\n\u001b[0;32m      4\u001b[0m kernel_sizes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m), (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m----> 5\u001b[0m fk_vcnn \u001b[38;5;241m=\u001b[39m \u001b[43mFacialKeypointVCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(fk_vcnn)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'linear_layers' and 'dropout_threshold'"
     ]
    }
   ],
   "source": [
    "cnn_layers = 3\n",
    "input_channels = 1\n",
    "output_channels = [32, 64, 96, 128, 512]\n",
    "kernel_sizes = [(5,5), (3,3), (3,3)]\n",
    "linear_layers = [512]\n",
    "fk_vcnn = FacialKeypointVCNN(cnn_layers, input_channels, output_channels, kernel_sizes).to(device)\n",
    "\n",
    "print(fk_vcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16c43899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(n_epochs):\n",
    "        \n",
    "    fk_vcnn.train()\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for batch_i, data in enumerate(train_loader):\n",
    "            # get the input images and their corresponding labels\n",
    "            images = data['image'].to(device)\n",
    "            keypoints = data['facial_landmarks'].to(device)\n",
    "            # flatten pts\n",
    "            keypoints = keypoints.view(keypoints.size(0), -1)\n",
    "            # convert variables to floats for regression loss\n",
    "            keypoints = keypoints.type(torch.FloatTensor)\n",
    "            images = images.type(torch.FloatTensor)\n",
    "            # forward pass to get outputs\n",
    "            output_pts = fk_vcnn(images.to(device))\n",
    "            # calculate the loss between predicted and target keypoints\n",
    "            optimization_functions = fk_vcnn.initialize_optimization_parameters()\n",
    "            loss = optimization_functions[\"criterion\"](output_pts.to(device), keypoints.to(device))\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimization_functions[\"optimizer\"].zero_grad()\n",
    "            # backward pass to calculate the weight gradients\n",
    "            loss.backward()\n",
    "            # update the weights\n",
    "            optimization_functions[\"optimizer\"].step()\n",
    "            # print loss statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if batch_i % 10 == 6:    # print every 7 batches\n",
    "                print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, running_loss/10))\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c53a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 1, Batch: 7, Avg. Loss: 9120.9943359375\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 2, Batch: 7, Avg. Loss: 2686.9764404296875\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 3, Batch: 7, Avg. Loss: 2391.35419921875\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 4, Batch: 7, Avg. Loss: 2387.54892578125\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 5, Batch: 7, Avg. Loss: 2128.3158325195313\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 6, Batch: 7, Avg. Loss: 2077.3695556640623\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 7, Batch: 7, Avg. Loss: 1928.9585693359375\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 8, Batch: 7, Avg. Loss: 1759.5279907226563\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 9, Batch: 7, Avg. Loss: 2382.7605224609374\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 10, Batch: 7, Avg. Loss: 1838.1984985351562\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 11, Batch: 7, Avg. Loss: 1893.5278442382812\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 12, Batch: 7, Avg. Loss: 1884.7734252929688\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 13, Batch: 7, Avg. Loss: 1739.11083984375\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 14, Batch: 7, Avg. Loss: 2071.31904296875\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 15, Batch: 7, Avg. Loss: 2478.5987060546877\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 16, Batch: 7, Avg. Loss: 1779.7482482910157\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 17, Batch: 7, Avg. Loss: 1989.5079711914063\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 18, Batch: 7, Avg. Loss: 1658.7217041015624\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 19, Batch: 7, Avg. Loss: 1639.4047058105468\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 20, Batch: 7, Avg. Loss: 1826.9183349609375\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 21, Batch: 7, Avg. Loss: 1930.4933959960938\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 22, Batch: 7, Avg. Loss: 2332.033349609375\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 23, Batch: 7, Avg. Loss: 1688.0751098632813\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 24, Batch: 7, Avg. Loss: 1939.0046997070312\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 25, Batch: 7, Avg. Loss: 2111.6864990234376\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 26, Batch: 7, Avg. Loss: 2019.6990234375\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 27, Batch: 7, Avg. Loss: 1634.5024047851562\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 28, Batch: 7, Avg. Loss: 1966.8956909179688\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 29, Batch: 7, Avg. Loss: 2124.8591430664064\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 30, Batch: 7, Avg. Loss: 2142.8401489257812\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 31, Batch: 7, Avg. Loss: 1920.8494995117187\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 32, Batch: 7, Avg. Loss: 2053.482287597656\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 33, Batch: 7, Avg. Loss: 2172.6018798828127\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 34, Batch: 7, Avg. Loss: 1659.6895629882813\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 35, Batch: 7, Avg. Loss: 1938.6260375976562\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 36, Batch: 7, Avg. Loss: 2298.2150024414063\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 37, Batch: 7, Avg. Loss: 1831.3736938476563\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 38, Batch: 7, Avg. Loss: 2066.562841796875\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 39, Batch: 7, Avg. Loss: 1669.617138671875\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 40, Batch: 7, Avg. Loss: 1512.2993041992188\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 41, Batch: 7, Avg. Loss: 1905.633740234375\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 42, Batch: 7, Avg. Loss: 2416.6483642578123\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 43, Batch: 7, Avg. Loss: 1752.6164306640626\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 44, Batch: 7, Avg. Loss: 1656.3124389648438\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 45, Batch: 7, Avg. Loss: 2259.8673095703125\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 46, Batch: 7, Avg. Loss: 1734.4904663085938\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 47, Batch: 7, Avg. Loss: 1612.7246337890624\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 48, Batch: 7, Avg. Loss: 1614.2272338867188\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 49, Batch: 7, Avg. Loss: 1801.5197143554688\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 50, Batch: 7, Avg. Loss: 2106.38623046875\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 51, Batch: 7, Avg. Loss: 1803.9698486328125\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 52, Batch: 7, Avg. Loss: 1839.932666015625\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 53, Batch: 7, Avg. Loss: 1915.0534423828126\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 54, Batch: 7, Avg. Loss: 1643.1319580078125\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 55, Batch: 7, Avg. Loss: 1847.9797119140626\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 56, Batch: 7, Avg. Loss: 1594.3772827148437\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 57, Batch: 7, Avg. Loss: 2217.4442626953123\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 58, Batch: 7, Avg. Loss: 1843.234423828125\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 59, Batch: 7, Avg. Loss: 1739.9875854492188\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 60, Batch: 7, Avg. Loss: 1327.787353515625\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 61, Batch: 7, Avg. Loss: 1728.6751098632812\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([10, 128, 26, 26])\n",
      "Input size before flattening: torch.Size([9, 128, 26, 26])\n",
      "Epoch: 62, Batch: 7, Avg. Loss: 1637.4060424804688\n"
     ]
    }
   ],
   "source": [
    "fit_model(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d703e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
